# XiaoZhi ESP32 - Custom Server HÆ°á»›ng Dáº«n Chi Tiáº¿t

## ğŸ“Œ Má»¥c Ä‘Ã­ch

Server WebSocket tá»‘i giáº£n Ä‘á»ƒ giao tiáº¿p vá»›i client **xiaozhi-esp32**.  
Má»¥c tiÃªu: hiá»ƒu rÃµ **tá»«ng Ä‘iá»ƒm cáº§n can thiá»‡p** khi muá»‘n tá»± build server riÃªng.

---

## ğŸ—ï¸ Kiáº¿n trÃºc tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ESP32 Client (xiaozhi-esp32)                  â”‚
â”‚                                                                      â”‚
â”‚  MIC â†’ Audio Processor â†’ Opus Encoder â†’ â”€â”€â”€â”€ WebSocket â”€â”€â”€â”€â†’ Server â”‚
â”‚  Speaker â† Opus Decoder â† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket â†â”€â”€â”€â”€â”€â”€â”€â”€ Server  â”‚
â”‚  Display â† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ JSON text â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Server   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                           â”‚
         â”‚  1. hello (JSON)                          â”‚
         â”‚  2. listen start/stop (JSON)              â”‚
         â”‚  3. binary audio frames (Opus 60ms)       â”‚
         â”‚  4. abort (JSON)                          â”‚
         â”‚                                           â”‚
         â”‚          Server tráº£ vá»:                   â”‚
         â”‚  1. hello response (JSON)                 â”‚
         â”‚  2. stt result (JSON)                     â”‚
         â”‚  3. tts start/sentence_start/stop (JSON)  â”‚
         â”‚  4. binary audio frames (Opus 60ms)       â”‚
         â”‚  5. llm emotion (JSON)                    â”‚
```

---

## ğŸ“ Cáº¥u trÃºc file

```
custom-server/
â”œâ”€â”€ server.py           â† ToÃ n bá»™ server trong 1 file (cÃ³ comment chi tiáº¿t)
â”œâ”€â”€ requirements.txt    â† Dependencies
â””â”€â”€ README.md           â† File nÃ y
```

---

## ğŸš€ CÃ¡ch cháº¡y

### 1. CÃ i dependencies

```bash
cd custom-server
pip install -r requirements.txt
```

NgoÃ i ra cáº§n cÃ i **ffmpeg** (dÃ¹ng cho TTS convert MP3 â†’ PCM):
```bash
# Ubuntu/Debian
sudo apt install ffmpeg

# macOS
brew install ffmpeg
```

VÃ  cáº§n cÃ i **libopus** (cho opuslib):
```bash
# Ubuntu/Debian
sudo apt install libopus-dev

# macOS
brew install opus
```

### 2. Äáº·t API key

```bash
export OPENAI_API_KEY="sk-your-key-here"
# Náº¿u dÃ¹ng provider khÃ¡c (Ollama, vLLM...):
export OPENAI_BASE_URL="http://localhost:11434/v1"
```

### 3. Cháº¡y server

```bash
python server.py
```

Server sáº½ láº¯ng nghe táº¡i `ws://0.0.0.0:8000`

### 4. Trá» ESP32 client vá» server

TrÃªn ESP32, khi device gá»i OTA check version, server OTA tráº£ config chá»©a WebSocket URL. Báº¡n cáº§n sá»­a OTA response Ä‘á»ƒ tráº£:

```json
{
  "websocket": {
    "url": "ws://YOUR_SERVER_IP:8000",
    "token": "your-token"
  }
}
```

Hoáº·c dÃ¹ng MQTT config tÃ¹y protocol báº¡n chá»n.

---

## ğŸ” Giáº£i thÃ­ch chi tiáº¿t tá»«ng pháº§n code

### PHáº¦N 1: CONFIG (dÃ²ng 68-87)

```python
CONFIG = {
    "server": {"host": "0.0.0.0", "port": 8000},
    "audio": {
        "input_sample_rate": 16000,    # Client gá»­i 16kHz
        "output_sample_rate": 24000,   # Server tráº£ 24kHz
        "input_frame_duration_ms": 60, # Má»—i frame 60ms
    },
    "openai": {...},  # API cho STT vÃ  LLM
    "tts": {"voice": "vi-VN-HoaiMyNeural"},  # Giá»ng TTS
}
```

**Can thiá»‡p:**
- Äá»•i `output_sample_rate` thÃ nh 16000 náº¿u muá»‘n tiáº¿t kiá»‡m bandwidth
- Äá»•i `voice` Ä‘á»ƒ thay giá»ng nÃ³i
- Äá»•i `base_url` Ä‘á»ƒ trá» Ä‘áº¿n Ollama/vLLM local

---

### PHáº¦N 2: OPUS ENCODER/DECODER (dÃ²ng 93-136)

Client ESP32 **chá»‰ há»— trá»£ Opus codec**. Server cáº§n:
- **Decoder**: nháº­n Opus tá»« client â†’ PCM Ä‘á»ƒ lÃ m STT
- **Encoder**: PCM tá»« TTS â†’ Opus gá»­i vá» client

```python
class OpusHelper:
    def decode_opus_to_pcm(self, opus_data: bytes) -> bytes:
        # 1 frame Opus 60ms â†’ 960 samples PCM 16-bit
    
    def encode_pcm_to_opus(self, pcm_data: bytes) -> bytes:
        # 1 frame PCM â†’ 1 gÃ³i Opus
```

**Can thiá»‡p:** KhÃ´ng cáº§n thay Ä‘á»•i vÃ¬ client chá»‰ há»— trá»£ Opus.

---

### PHáº¦N 3: STT - Speech To Text (dÃ²ng 146-198)

Nháº­n PCM audio â†’ gá»i API â†’ tráº£ text.

```python
class SimpleSTT:
    async def transcribe(self, pcm_data, sample_rate=16000) -> str:
        # PCM â†’ WAV â†’ gá»­i lÃªn Whisper API â†’ text
```

**Luá»“ng:** Batch mode (Ä‘á»£i user nÃ³i xong má»›i xá»­ lÃ½)

**Can thiá»‡p chÃ­nh:**
| Muá»‘n lÃ m | Sá»­a á»Ÿ Ä‘Ã¢u |
|-----------|-----------|
| DÃ¹ng Whisper local | Thay body `transcribe()`, import `faster_whisper` |
| DÃ¹ng Google Speech | Thay API call |
| Streaming STT (giáº£m latency) | Nháº­n audio frame â†’ gá»­i real-time, nháº­n partial text |
| Äá»•i ngÃ´n ngá»¯ | Thay `language="vi"` thÃ nh ngÃ´n ngá»¯ khÃ¡c |

---

### PHáº¦N 4: LLM - Large Language Model (dÃ²ng 208-261)

Nháº­n text â†’ gá»i LLM API **streaming** â†’ yield tá»«ng chunk.

```python
class SimpleLLM:
    async def chat_stream(self, user_text, history):
        # Gá»i OpenAI-compatible API vá»›i stream=True
        async for chunk in stream:
            yield chunk.choices[0].delta.content
```

**Streaming ráº¥t quan trá»ng!** Náº¿u khÃ´ng stream, user pháº£i Ä‘á»£i toÃ n bá»™ response â†’ latency cao.

**Can thiá»‡p chÃ­nh:**
| Muá»‘n lÃ m | Sá»­a á»Ÿ Ä‘Ã¢u |
|-----------|-----------|
| DÃ¹ng Ollama | Äá»•i `base_url` thÃ nh `http://localhost:11434/v1` |
| DÃ¹ng Claude | Thay báº±ng Anthropic SDK |
| ThÃªm RAG | ThÃªm context tá»« vector DB vÃ o messages |
| ThÃªm system prompt | Sá»­a `self.system_prompt` |
| Function calling | ThÃªm `tools` param vÃ o `create()` |

---

### PHáº¦N 5: TTS - Text To Speech (dÃ²ng 272-332)

Nháº­n text â†’ audio PCM â†’ encode Opus frames.

```python
class SimpleTTS:
    async def synthesize_to_opus(self, text):
        # text â†’ edge-tts (MP3) â†’ ffmpeg (PCM) â†’ Opus frames
        for opus_frame in frames:
            yield opus_frame
```

**Can thiá»‡p chÃ­nh:**
| Muá»‘n lÃ m | Sá»­a á»Ÿ Ä‘Ã¢u |
|-----------|-----------|
| Giá»ng khÃ¡c | Äá»•i `voice` trong CONFIG |
| DÃ¹ng VITS/Coqui | Thay toÃ n bá»™ body `synthesize_to_opus()` |
| Azure TTS | Thay edge-tts báº±ng Azure SDK |
| Tá»‘c Ä‘á»™ nÃ³i | ThÃªm param rate vÃ o edge-tts |

---

### PHáº¦N 6: SESSION (dÃ²ng 341-364)

Quáº£n lÃ½ tráº¡ng thÃ¡i 1 káº¿t ná»‘i:

```python
class Session:
    self.pcm_buffer = bytearray()    # TÃ­ch lÅ©y audio tá»« client
    self.chat_history = []           # Lá»‹ch sá»­ chat cho LLM
    self.is_speaking = False         # Server Ä‘ang phÃ¡t audio?
    self.aborted = False             # Client yÃªu cáº§u dá»«ng?
```

**Can thiá»‡p:** ThÃªm user profile, persistent memory, device registry...

---

### PHáº¦N 7: WEBSOCKET HANDLER (dÃ²ng 378-590) â­ QUAN TRá»ŒNG NHáº¤T

ÄÃ¢y lÃ  core xá»­ lÃ½ message. Má»—i hÃ m handle 1 loáº¡i message:

#### 7.1 Main loop
```python
async for message in self.ws:
    if isinstance(message, str):   â†’ JSON message (hello/listen/abort/mcp)
    elif isinstance(message, bytes): â†’ Binary audio (Opus frames)
```

#### 7.2 PhÃ¢n loáº¡i message
```python
msg_type = msg.get("type")
if msg_type == "hello":    â†’ _handle_hello()
elif msg_type == "listen": â†’ _handle_listen()  
elif msg_type == "abort":  â†’ _handle_abort()
elif msg_type == "mcp":    â†’ _handle_mcp()
```

#### 7.3 Hello handshake âš ï¸ Báº®T BUá»˜C

```
Client gá»­i:                          Server PHáº¢I tráº£:
{                                    {
  "type": "hello",                     "type": "hello",
  "version": 1,                       "transport": "websocket",  â† PHáº¢I KHá»šP
  "transport": "websocket",           "session_id": "uuid...",
  "audio_params": {                   "audio_params": {
    "format": "opus",                   "sample_rate": 24000,
    "sample_rate": 16000,               "channels": 1,
    "channels": 1,                      "frame_duration": 60
    "frame_duration": 60               }
  }                                  }
}
```

**Náº¿u server khÃ´ng tráº£ hello Ä‘Ãºng format trong 10 giÃ¢y â†’ client bÃ¡o timeout!**

#### 7.4 Listen state machine
```
listen start â†’ XÃ³a buffer, sáºµn sÃ ng nháº­n audio
listen stop  â†’ Trigger pipeline: STT â†’ LLM â†’ TTS
listen detect â†’ Wake word detected
```

#### 7.5 Abort
```
Client abort â†’ Server dá»«ng gá»­i audio ngay láº­p tá»©c
```

#### 7.8 Pipeline STT â†’ LLM â†’ TTS â­

```python
async def _process_conversation(self):
    # 1. STT: PCM buffer â†’ text
    user_text = await self.session.stt.transcribe(pcm_data)
    
    # 2. Gá»­i STT result vá» client (hiá»ƒn thá»‹)
    await self._send_stt(user_text)
    
    # 3. LLM streaming â†’ tÃ¡ch cÃ¢u â†’ TTS â†’ gá»­i audio
    await self._stream_llm_tts_response(user_text)
```

#### 7.9 Streaming response (giáº£m latency)

```python
async def _stream_llm_tts_response(self, user_text):
    await self._send_tts_state("start")          # BÃ¡o client báº¯t Ä‘áº§u nghe
    
    async for chunk in self.session.llm.chat_stream(...):
        sentence_buffer += chunk
        if gáº·p_dáº¥u_cháº¥m:
            await self._send_tts_sentence(cÃ¢u)    # Hiá»ƒn thá»‹ text
            await self._synthesize_and_send(cÃ¢u)   # Gá»­i audio
    
    await self._send_tts_state("stop")            # BÃ¡o client xong
```

**Chiáº¿n lÆ°á»£c tÃ¡ch cÃ¢u:** TÃ­ch lÅ©y token tá»« LLM, khi gáº·p dáº¥u cÃ¢u (. ! ? ã€‚) â†’ gá»­i ngay cho TTS â†’ client báº¯t Ä‘áº§u nghe trong khi LLM váº«n sinh tiáº¿p.

---

## ğŸ“Š So sÃ¡nh vá»›i xiaozhi-esp32-server chÃ­nh thá»©c

| TÃ­nh nÄƒng | Custom Server (file nÃ y) | xiaozhi-esp32-server |
|-----------|-------------------------|---------------------|
| WebSocket | âœ… CÆ¡ báº£n | âœ… Äáº§y Ä‘á»§ + MQTT |
| Hello handshake | âœ… | âœ… |
| STT | âœ… Batch (Whisper API) | âœ… Streaming + nhiá»u provider |
| LLM | âœ… Streaming (OpenAI) | âœ… Streaming + nhiá»u provider |
| TTS | âœ… edge-tts | âœ… Nhiá»u TTS engine |
| VAD | âŒ ChÆ°a cÃ³ | âœ… Silero VAD |
| MCP/IoT | âŒ ChÆ°a implement | âœ… Äáº§y Ä‘á»§ |
| Auth | âŒ | âœ… JWT + device whitelist |
| Memory | âŒ | âœ… Chat memory |
| Intent | âŒ | âœ… Intent detection |
| Multi-device | âŒ | âœ… |
| Rate control | âŒ | âœ… AudioRateController |
| OTA server | âŒ | âœ… HTTP server |

---

## ğŸ¯ Roadmap custom tiáº¿p

### 1. ThÃªm VAD (Voice Activity Detection)
Äá»ƒ server tá»± detect khi user ngá»«ng nÃ³i (mode="auto"):
```python
# pip install silero-vad
# Trong _handle_audio_data(), sau khi decode Opus:
is_voice = vad.is_speech(pcm_frame)
if was_speaking and not is_voice:
    # User ngá»«ng nÃ³i â†’ trigger _process_conversation()
```

### 2. ThÃªm Streaming STT
Thay vÃ¬ Ä‘á»£i user nÃ³i xong má»›i STT:
```python
# Má»—i frame audio nháº­n Ä‘Æ°á»£c â†’ gá»­i real-time cho STT engine
# STT tráº£ partial result â†’ update liÃªn tá»¥c
# Khi user dá»«ng â†’ STT tráº£ final result
```

### 3. ThÃªm MCP (IoT Control)
```python
# Sau hello, gá»­i MCP initialize:
await self._send_json({
    "type": "mcp",
    "payload": {
        "jsonrpc": "2.0",
        "method": "initialize",
        "params": {"capabilities": {}},
        "id": 1
    }
})
# Sau Ä‘Ã³ gá»i tools/list Ä‘á»ƒ láº¥y danh sÃ¡ch tool tá»« device
# LLM quyáº¿t Ä‘á»‹nh khi nÃ o gá»i tool
```

### 4. ThÃªm OTA HTTP Server
ESP32 cáº§n 1 HTTP endpoint Ä‘á»ƒ láº¥y config:
```python
# GET /xiaozhi/ota/ â†’ tráº£ config JSON chá»©a websocket URL, token...
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [WebSocket Protocol](../xiaozhi-esp32/docs/websocket.md) - Chi tiáº¿t protocol
- [MQTT+UDP Protocol](../xiaozhi-esp32/docs/mqtt-udp.md) - Protocol thay tháº¿
- [MCP Protocol](../xiaozhi-esp32/docs/mcp-protocol.md) - IoT control
- [MCP Usage](../xiaozhi-esp32/docs/mcp-usage.md) - CÃ¡ch dÃ¹ng MCP
- [xiaozhi-esp32-server](../xiaozhi-esp32-server/) - Server chÃ­nh thá»©c (tham kháº£o)
